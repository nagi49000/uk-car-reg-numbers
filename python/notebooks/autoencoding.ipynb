{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a simple autoencoder\n",
    "\n",
    "Based on the ability to generate UK car registration numbers, one can build a dataset of training and test data. With a suitable vectorizer, one can go ahead and make an autoencoder.\n",
    "\n",
    "### References\n",
    "\n",
    "https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras import layers\n",
    "import random\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from car_reg_generator.car_reg_generator.uk_reg import UkRegGenerator\n",
    "from car_reg_generator.car_reg_generator.uk_reg import UkRegBowVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n"
     ]
    }
   ],
   "source": [
    "n_train = 10000\n",
    "n_test = 1000\n",
    "\n",
    "random.seed(0)\n",
    "g = UkRegGenerator()\n",
    "v = UkRegBowVectorizer()\n",
    "\n",
    "train_strs = [g.get_reg() for _ in range(n_train)]\n",
    "train_vecs = np.array([v.vectorize(x) for x in train_strs])\n",
    "test_strs = [g.get_reg() for _ in range(n_test)]\n",
    "test_vecs = np.array([v.vectorize(x) for x in test_strs])\n",
    "\n",
    "vec_length = len(train_vecs[0])\n",
    "print(vec_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard autoencoder\n",
    "\n",
    "Design the network. A single dense layer for the encoder and decoder needs an encoding dimension of around 100. Having more layers allows a smaller encoding dimension, although convergence during learning starts to become unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 30\n",
    "input_reg = keras.Input(shape=(vec_length,))\n",
    "# encoded = layers.Dense(encoding_dim, activation='relu', activity_regularizer=regularizers.l1(10e-5))(input_reg)\n",
    "encoded = layers.Dense(vec_length, activation='relu')(input_reg)\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(encoded)\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(encoded)\n",
    "encoder = keras.Model(input_reg, encoded)\n",
    "\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "decoded = layers.Dense(encoding_dim, activation='relu')(encoded_input)\n",
    "decoded = layers.Dense(vec_length, activation='relu')(decoded)\n",
    "decoded = layers.Dense(vec_length, activation='sigmoid')(decoded)\n",
    "decoder = keras.Model(encoded_input, decoded)\n",
    "\n",
    "autoencoder = keras.Model(input_reg, decoder(encoder(input_reg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some learning. For shallow networks, almost any optimizer and loss work. For deeper networks, poor choices almost certainly yield failed convergence on the loss function. Even good choices yield convergence on the loss function only on some runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 36.3037 - val_loss: 34.4503\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 34.2977 - val_loss: 34.0804\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 33.5283 - val_loss: 32.7403\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 32.2608 - val_loss: 31.8873\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 31.4694 - val_loss: 31.1515\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 30.7854 - val_loss: 30.6665\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 30.2135 - val_loss: 30.0432\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 29.5821 - val_loss: 29.4553\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 28.7802 - val_loss: 28.6910\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 28.0166 - val_loss: 28.1754\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 27.4403 - val_loss: 27.6422\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 26.8938 - val_loss: 27.1040\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 26.4124 - val_loss: 26.7607\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 25.9095 - val_loss: 26.1997\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 25.4394 - val_loss: 25.8573\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 25.0317 - val_loss: 25.4500\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 24.5517 - val_loss: 24.9419\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 23.9500 - val_loss: 24.3569\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 23.5327 - val_loss: 23.8967\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 23.0355 - val_loss: 23.3945\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 22.6127 - val_loss: 23.1438\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 22.2603 - val_loss: 22.6101\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 21.8536 - val_loss: 22.2387\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 21.4642 - val_loss: 21.7737\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 21.1034 - val_loss: 21.5044\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 20.8151 - val_loss: 21.1509\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 20.4472 - val_loss: 20.9098\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 20.1422 - val_loss: 20.5698\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 19.8035 - val_loss: 20.3975\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 19.5324 - val_loss: 20.0611\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 19.2616 - val_loss: 19.6336\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 19.0395 - val_loss: 19.7160\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 18.7976 - val_loss: 19.3158\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 18.4717 - val_loss: 18.9823\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 18.2828 - val_loss: 18.7256\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 18.0133 - val_loss: 18.4831\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 17.8160 - val_loss: 18.1743\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 17.5378 - val_loss: 18.1531\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 17.4352 - val_loss: 18.1260\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 17.3050 - val_loss: 17.6348\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 17.0746 - val_loss: 17.5604\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 16.8914 - val_loss: 17.3328\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 16.7485 - val_loss: 17.0926\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 16.5175 - val_loss: 16.9978\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 16.3967 - val_loss: 16.8754\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 16.2781 - val_loss: 16.7180\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 16.1234 - val_loss: 16.5740\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 15.9925 - val_loss: 16.2443\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 15.7613 - val_loss: 16.5131\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 15.7132 - val_loss: 16.0097\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 15.5238 - val_loss: 15.7809\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 15.3985 - val_loss: 15.9121\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 15.2415 - val_loss: 15.5190\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 15.0824 - val_loss: 15.4787\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 15.0038 - val_loss: 15.3094\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 14.9278 - val_loss: 15.2470\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 14.8009 - val_loss: 15.0440\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 14.6634 - val_loss: 15.0093\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 14.6453 - val_loss: 14.9000\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 14.5832 - val_loss: 14.8416\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 14.4838 - val_loss: 14.6818\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 14.3940 - val_loss: 14.6317\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 14.3546 - val_loss: 14.5716\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 14.3148 - val_loss: 14.4754\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 14.2494 - val_loss: 14.4345\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 14.1867 - val_loss: 14.3502\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 14.1521 - val_loss: 14.3400\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 14.1479 - val_loss: 14.2498\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 14.1086 - val_loss: 14.2579\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 14.0358 - val_loss: 14.1702\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 13.9911 - val_loss: 14.1483\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 13.9969 - val_loss: 14.1103\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 13.9509 - val_loss: 14.0511\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 13.9248 - val_loss: 14.0733\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 13.8916 - val_loss: 14.0373\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 13.9006 - val_loss: 14.0458\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 13.8717 - val_loss: 14.0040\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 13.8949 - val_loss: 14.0230\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 13.9681 - val_loss: 14.0141\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 19ms/step - loss: 13.8572 - val_loss: 13.9608\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 13.9228 - val_loss: 14.2789\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 13.8971 - val_loss: 13.9412\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 13.8032 - val_loss: 13.8801\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 13.7923 - val_loss: 13.8908\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 13.7943 - val_loss: 13.9603\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 13.7876 - val_loss: 13.8569\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 13.7626 - val_loss: 13.8360\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 13.7457 - val_loss: 13.8489\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 13.7782 - val_loss: 13.8182\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 13.7474 - val_loss: 13.8211\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 13.7281 - val_loss: 13.7902\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 13.7158 - val_loss: 13.8135\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 13.7142 - val_loss: 13.7897\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 13.7350 - val_loss: 13.8261\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 13.7380 - val_loss: 13.7827\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 13.7171 - val_loss: 13.7949\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 13.7381 - val_loss: 13.8751\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 15.0263 - val_loss: 15.0905\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 14.2466 - val_loss: 14.0175\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 13.8358 - val_loss: 13.8283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcd40744a60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "autoencoder.fit(train_vecs, train_vecs,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_vecs, test_vecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AN45FVI', 'LE23DCR', 'HA99JWO', 'EQ58XKI', 'RP49FNK', 'DJ61XIM', 'WO62NON', 'EA42JCE', 'DV47KTZ', 'HM70DFU']\n",
      "['AN45FVI', 'LE23DCR', 'HA99JWO', 'EQ58XKI', 'RP49FNK', 'DJ61XIM', 'WO62NON', 'EA42JCE', 'DV47KTZ', 'HM70DFU']\n",
      "accuracy = 0.996\n"
     ]
    }
   ],
   "source": [
    "decoded_regs = autoencoder.predict(test_vecs)\n",
    "print(test_strs[:10])\n",
    "print([v.recover(x) for x in decoded_regs[:10]])\n",
    "acc = np.sum([v.recover(x) == y for x, y in zip(decoded_regs, test_strs)]) / len(test_strs)\n",
    "print('accuracy = ' + str(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
